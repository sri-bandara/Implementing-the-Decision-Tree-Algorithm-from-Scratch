# Implementing-the-Decision-Tree-Algorithm-from-Scratch

#### <span style="font-size: 18px; color: #000000; font-weight: bold;">Context</span>
<p style="font-size: 15px; color: #333333;">
    This repository demonstrates how to implement the Decision tree algorithm completely from scratch using Python and NumPy. The objective of this project was to gain a deeper understanding of how the algorithm works internally by manually coding each step of the algorithm rather than relying on high-level libraries like scikit-learn.
</p>

#### <span style="font-size: 18px; color: #000000; font-weight: bold;">Dataset</span>
<p style="font-size: 15px; color: #333333;">
    This dataset was extracted from an exercise available in Andrew Ng's Machine Learning Specialization. The specialization is offered by Stanford Online and DeepLearning.AI through Coursera.
</p>

#### <span style="font-size: 18px; color: #000000; font-weight: bold;">Process</span>
<p style="font-size: 15px; color: #333333;">
    The code includes implementation of the compute entropy function, split dataset function, compute information gain function, get best split function and build tree recursive function. The algorithm was tested on a dataset for evaluation.
</p>

#### <span style="font-size: 18px; color: #000000; font-weight: bold;">Acknowledgements</span>
<p style="font-size: 16px; color: #333333;">
The dataset and much of the inspiration for this implementation comes from the  <a href="https://www.coursera.org/specializations/machine-learning-introduction" target="_blank" style="color: #0066cc; text-decoration: none;">Machine Learning Specialization</a>. This project is based on the teachings and exercises from the specializationâ€™s second course,  <a href="https://www.coursera.org/learn/advanced-learning-algorithms" target="_blank" style="color: #0066cc; text-decoration: none;">
Advanced Learning Algorithms</a>.

Special thanks to Andrew Ng for providing a clear and accessible introduction to core machine learning concepts.

</p>
